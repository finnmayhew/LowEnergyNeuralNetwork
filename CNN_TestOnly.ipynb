{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook version of CNN_TestOnly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# Version of CNN on 12 May 2020\n",
    "# \n",
    "# Evaluates net for given model and plots\n",
    "# Takes in ONE file to Test on, can compare to old reco\n",
    "# Runs Energy, Zenith, Track length (1 variable energy or zenith, 2 = energy then zenith, 3 = EZT)\n",
    "#   Inputs:\n",
    "#       -i input_file:  name of ONE file \n",
    "#       -d path:        path to input files\n",
    "#       -o ouput_dir:   path to output_plots directory\n",
    "#       -n name:        name for folder in output_plots that has the model you want to load\n",
    "#       -e epochs:      epoch number of the model you want to load\n",
    "#       --variables:    Number of variables to train for (1 = energy or zenith, 2 = EZ, 3 = EZT)\n",
    "#       --first_variable: Which variable to train for, energy or zenith (for num_var = 1 only)\n",
    "#       --compare_reco: boolean flag, true means you want to compare to a old reco (pegleg, retro, etc.)\n",
    "#       -t test:        Name of reco to compare against, with \"oscnext\" used for no reco to compare with\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import h5py\n",
    "import time\n",
    "import os, sys\n",
    "import matplotlib\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/users/jmicallef/LowEnergyNeuralNetwork/output_plots/numu_flat_Z_5_100_CC_uncleaned_cleanedpulsesonly_3600kevents_nologcharge_IC19_lrEpochs50/oscnext_175epochs/\n",
      "Test type: oscnext\n"
     ]
    }
   ],
   "source": [
    "contained = False\n",
    "first_var = \"zenith\" #zenith or energy\n",
    "compare_reco = False\n",
    "\n",
    "\n",
    "indir = \"/data/icecube/jmicallef/processed_CNN_files/\"\n",
    "# Expects one file\n",
    "input_file = \"NuMu_140000_level2_uncleaned_cleanedpulsesonly_vertexDC_IC19_flat_95bins_36034evtperbin_CC.lt100.transformedinputstatic_transformed3output.testonly.hdf5\" \n",
    "if contained:\n",
    "    input_file = \"NuMu_140000_level2_uncleaned_cleanedpulsesonly_vertexDC_IC19_flat_95bins_36034evtperbin_CC.lt100_contained.testonly.hdf5\"\n",
    "outdir = \"/home/users/jmicallef/LowEnergyNeuralNetwork/\"\n",
    "test_file = indir + input_file\n",
    "reco_name = \"oscnext\"\n",
    "\n",
    "# Set up for \n",
    "if first_var == \"zenith\":\n",
    "    letter=\"Z\"\n",
    "if first_var == \"energy\":\n",
    "    letter=\"E\"\n",
    "if contained:\n",
    "    filename = \"numu_flat_%s_5_100_CC_uncleaned_cleanedpulsesonly_3600kevents_nologcharge_oldvertexDC_lrEpochs50_containedIC19\"%letter\n",
    "    epoch = 252\n",
    "else:\n",
    "    filename = \"numu_flat_%s_5_100_CC_uncleaned_cleanedpulsesonly_3600kevents_nologcharge_IC19_lrEpochs50\"%letter\n",
    "    epoch = 175\n",
    "\n",
    "output_variables = 1\n",
    "if compare_reco:\n",
    "    reco_name = \"PegLeg\"\n",
    "    if contained:\n",
    "        input_file = \"Level5p_IC86.2013_genie_numu.014640.IC19_vertexDC_CC.lt100.transformedinputstatic_transformed3output_file00_contained.testonly.hdf5\"\n",
    "    else:\n",
    "        input_file = \"Level5p_IC86.2013_genie_numu.014640.lt200_vertexDCCC.lt100.transformedinputstatic_transformed3output.testonly.hdf5\"\n",
    "    \n",
    "\n",
    "\n",
    "dropout = 0.2\n",
    "learning_rate = 1e-3\n",
    "DC_drop_value = dropout\n",
    "IC_drop_value = dropout\n",
    "connected_drop_value = dropout\n",
    "min_energy = 5\n",
    "max_energy = 100.\n",
    "\n",
    "save = True\n",
    "save_folder_name = \"%soutput_plots/%s/\"%(outdir,filename)\n",
    "if save==True:\n",
    "    if os.path.isdir(save_folder_name) != True:\n",
    "        os.mkdir(save_folder_name)\n",
    "load_model_name = \"%s%s_%iepochs_model.hdf5\"%(save_folder_name,filename,epoch) \n",
    "use_old_weights = True\n",
    "\n",
    "save_folder_name += \"%s_%sepochs/\"%(reco_name,epoch)\n",
    "if os.path.isdir(save_folder_name) != True:\n",
    "    os.mkdir(save_folder_name)\n",
    "print(save_folder_name)\n",
    "print(\"Test type: %s\"%reco_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data from testonly file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on /data/icecube/jmicallef/processed_CNN_files/NuMu_140000_level2_uncleaned_cleanedpulsesonly_vertexDC_IC19_flat_95bins_36034evtperbin_CC.lt100.transformedinputstatic_transformed3output.testonly.hdf5\n",
      "(342328, 8, 60, 5) (342328, 19, 60, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing on %s\"%test_file)\n",
    "f = h5py.File(test_file, 'r')\n",
    "Y_test_use = f['Y_test'][:]\n",
    "X_test_DC_use = f['X_test_DC'][:]\n",
    "X_test_IC_use = f['X_test_IC'][:]\n",
    "if compare_reco:\n",
    "    reco_test_use = f['reco_test'][:]\n",
    "f.close\n",
    "del f\n",
    "print(X_test_DC_use.shape,X_test_IC_use.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from PlottingChecks import plot_output\n",
    "plot_output(Y_test_use,save_folder_name,filenumber=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Net (Load Model, Set Loss Function, Compile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(342328, 8, 60, 5) (342328, 19, 60, 5)\n",
      "WARNING:tensorflow:From /home/users/jmicallef/anaconda3/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/users/jmicallef/anaconda3/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/users/jmicallef/anaconda3/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/users/jmicallef/anaconda3/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/users/jmicallef/anaconda3/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/users/jmicallef/anaconda3/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/users/jmicallef/anaconda3/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/users/jmicallef/anaconda3/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/users/jmicallef/anaconda3/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/users/jmicallef/anaconda3/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/users/jmicallef/anaconda3/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/users/jmicallef/anaconda3/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/users/jmicallef/anaconda3/envs/tfgpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Loading model /home/users/jmicallef/LowEnergyNeuralNetwork/output_plots/numu_flat_Z_5_100_CC_uncleaned_cleanedpulsesonly_3600kevents_nologcharge_IC19_lrEpochs50/numu_flat_Z_5_100_CC_uncleaned_cleanedpulsesonly_3600kevents_nologcharge_IC19_lrEpochs50_175epochs_model.hdf5\n"
     ]
    }
   ],
   "source": [
    "#Make network and load model\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from cnn_model import make_network\n",
    "print(X_test_DC_use.shape,X_test_IC_use.shape)\n",
    "model_DC = make_network(X_test_DC_use,X_test_IC_use,output_variables,DC_drop_value,IC_drop_value,connected_drop_value)\n",
    "print(\"Loading model %s\"%load_model_name)\n",
    "#print(model_DC.summary())\n",
    "model_DC.load_weights(load_model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/users/jmicallef/anaconda3/envs/tfgpu/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "zenith first\n"
     ]
    }
   ],
   "source": [
    "# WRITE OWN LOSS FOR MORE THAN ONE REGRESSION OUTPUT\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.losses import mean_absolute_percentage_error\n",
    "\n",
    "if first_var == \"zenith\":\n",
    "    def ZenithLoss(y_truth,y_predicted):\n",
    "        #return logcosh(y_truth[:,1],y_predicted[:,1])\n",
    "        return mean_squared_error(y_truth[:,1],y_predicted[:,0])\n",
    "\n",
    "    def CustomLoss(y_truth,y_predicted):\n",
    "            zenith_loss = ZenithLoss(y_truth,y_predicted)\n",
    "            return zenith_loss\n",
    "\n",
    "    model_DC.compile(loss=ZenithLoss,\n",
    "                optimizer=Adam(lr=learning_rate),\n",
    "                metrics=[ZenithLoss])\n",
    "    \n",
    "    print(\"zenith first\")\n",
    "\n",
    "\n",
    "else: \n",
    "    def EnergyLoss(y_truth,y_predicted):\n",
    "        return mean_absolute_percentage_error(y_truth[:,0],y_predicted[:,0])\n",
    "\n",
    "    def ZenithLoss(y_truth,y_predicted):\n",
    "        return mean_squared_error(y_truth[:,1],y_predicted[:,1])\n",
    "\n",
    "    def TrackLoss(y_truth,y_predicted):\n",
    "        return mean_squared_logarithmic_error(y_truth[:,2],y_predicted[:,2])\n",
    "\n",
    "    if output_variables == 3:\n",
    "        def CustomLoss(y_truth,y_predicted):\n",
    "            energy_loss = EnergyLoss(y_truth,y_predicted)\n",
    "            zenith_loss = ZenithLoss(y_truth,y_predicted)\n",
    "            track_loss = TrackLoss(y_truth,y_predicted)\n",
    "            return energy_loss + zenith_loss + track_loss\n",
    "\n",
    "        model_DC.compile(loss=CustomLoss,\n",
    "                  optimizer=Adam(lr=learning_rate),\n",
    "                  metrics=[EnergyLoss,ZenithLoss,TrackLoss])\n",
    "\n",
    "    elif output_variables == 2:\n",
    "        def CustomLoss(y_truth,y_predicted):\n",
    "            energy_loss = EnergyLoss(y_truth,y_predicted)\n",
    "            zenith_loss = ZenithLoss(y_truth,y_predicted)\n",
    "            return energy_loss + zenith_loss\n",
    "\n",
    "        model_DC.compile(loss=CustomLoss,\n",
    "                  optimizer=Adam(lr=learning_rate),\n",
    "                  metrics=[EnergyLoss,ZenithLoss])\n",
    "    else:\n",
    "        def CustomLoss(y_truth,y_predicted):\n",
    "            energy_loss = EnergyLoss(y_truth,y_predicted)\n",
    "            return energy_loss\n",
    "\n",
    "        model_DC.compile(loss=EnergyLoss,\n",
    "                    optimizer=Adam(lr=learning_rate),\n",
    "                    metrics=[EnergyLoss])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run prediction\n",
    "t0 = time.time()\n",
    "Y_test_predicted = model_DC.predict([X_test_DC_use,X_test_IC_use])\n",
    "t1 = time.time()\n",
    "print(\"This took me %f seconds for %i events\"%(((t1-t0)),Y_test_predicted.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RMS(resolution):\n",
    "    mean_array = numpy.ones_like(resolution)*numpy.mean(resolution)\n",
    "    rms = numpy.sqrt( sum((mean_array - resolution)**2)/len(resolution) )\n",
    "    return rms\n",
    "\n",
    "def plot_length_energy(truth, nn_reco, emax=100., track_index=2,tmax=200.,\\\n",
    "                        save=False,savefolder=None,use_fraction=False\\\n",
    "                        bins=60,minval=None,maxval=None,ylim=None,\\\n",
    "                        cut_truth = False, axis_square =False, zmax=None,\n",
    "                        variable=\"Energy\", units = \"GeV\", epochs=None,reco_name=\"CNN\"):\n",
    "    \"\"\"\n",
    "    Plot testing set reconstruction vs truth\n",
    "    Recieves:\n",
    "        truth = array, Y_test truth\n",
    "        nn_reco = array, neural network prediction output\n",
    "        save = optional, bool to save plot\n",
    "        savefolder = optional, output folder to save to, if not in current dir\n",
    "        syst_set = string, name of the systematic set (for title and saving)\n",
    "        bins = int, number of bins plot (will use for both the x and y direction)\n",
    "        minval = float, minimum value to cut nn_reco results\n",
    "        maxval = float, maximum value to cut nn_reco results\n",
    "        cut_truth = bool, true if you want to make the value cut on truth rather than nn results\n",
    "        axis_square = bool, cut axis to be square based on minval and maxval inputs\n",
    "        variable = string, name of the variable you are plotting\n",
    "        units = string, units for the variable you are plotting\n",
    "    Returns:\n",
    "        2D plot of True vs Reco\n",
    "    \"\"\"\n",
    "\n",
    "    true_energy = truth[:,0]*emax\n",
    "    true_track_length =  truth[:,track_index]*tmax\n",
    "    \n",
    "    if use_fraction:\n",
    "        nn_resolution = (nn_reco - true_energy)/true_energy\n",
    "        title = \"Fractional %s Resolution\"%variable\n",
    "        zlabel = \"(reconstruction - truth) / truth\" \n",
    "    else:\n",
    "        nn_resolution = nn_reco - true_energy\n",
    "        title = \"%s Resolution\"%variable\n",
    "        zlabel = \"reconstruction - truth (%s)\"%units\n",
    "    \n",
    "    plt.figure(figsize=(10,7))\n",
    "    cts,xbin,ybin,img = plt.hist2d(true_energy, true_track_length, bins=bins, weights=nn_resolution, cmax=zmax)\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.ax.set_ylabel('counts', rotation=90)\n",
    "    plt.set_cmap('viridis_r')\n",
    "    plt.xlabel(\"True Neutrino Energy (GeV)\",fontsize=15)\n",
    "    plt.ylabel(\"True Track Length (m)\",fontsize=15)\n",
    "    plt.zlabel(zlabel,fontsize=15)\n",
    "    \n",
    "    if zmax:\n",
    "        nocut_name += \"_zmax%i\"%zmax    \n",
    "    if save:\n",
    "        plt.savefig(\"%sTrueEnergyTrackReco%s_2DHist%s.png\"%(savefolder,reco_name,nocut_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_length_energy(Y_test_use, Y_test_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAKE THE PLOTS ###\n",
    "from PlottingFunctions import plot_single_resolution\n",
    "from PlottingFunctions import plot_2D_prediction\n",
    "from PlottingFunctions import plot_2D_prediction_fraction\n",
    "from PlottingFunctions import plot_bin_slices\n",
    "from PlottingFunctions import plot_distributions\n",
    "\n",
    "plots_names = [\"Energy\", \"CosZenith\", \"Track\"]\n",
    "plots_units = [\"GeV\", \"\", \"m\"]\n",
    "maxabs_factors = [100., 1., 200.]\n",
    "#maxvals = [max_energy, 1., 0.]\n",
    "#minvals = [min_energy, -1., 0.]\n",
    "use_fractions = [True, False, True]\n",
    "bins_array = [95,100,100]\n",
    "if output_variables == 3: \n",
    "    maxvals = [max_energy, 1., max(Y_test_use[:,2])*maxabs_factor[2]]\n",
    "\n",
    "for num in range(0,output_variables):\n",
    "\n",
    "    NN_index = num\n",
    "    if first_var == \"energy\":\n",
    "        true_index = num\n",
    "        name_index = num\n",
    "    if first_var == \"zenith\":\n",
    "        true_index = first_var_index\n",
    "        name_index = first_var_index\n",
    "    plot_name = plots_names[name_index]\n",
    "    plot_units = plots_units[name_index]\n",
    "    maxabs_factor = maxabs_factors[name_index]\n",
    "    maxval = maxvals[name_index]\n",
    "    minval = minvals[name_index]\n",
    "    use_frac = use_fractions[name_index]\n",
    "    bins = bins_array[name_index]\n",
    "    print(\"Plotting %s at position %i in true test output and %i in NN test output\"%(plot_name, true_index,NN_index))\n",
    "    \n",
    "    plot_2D_prediction(Y_test_use[:,true_index]*maxabs_factor,\\\n",
    "                        Y_test_predicted[:,NN_index]*maxabs_factor,\\\n",
    "                        save,save_folder_name,bins=bins,\\\n",
    "                        minval=minval,maxval=maxval,\\\n",
    "                        variable=plot_name,units=plot_units, epochs=epoch)\n",
    "    plot_2D_prediction(Y_test_use[:,true_index]*maxabs_factor, Y_test_predicted[:,NN_index]*maxabs_factor,\\\n",
    "                        save,save_folder_name,bins=bins,\\\n",
    "                        minval=None,maxval=None,\\\n",
    "                        variable=plot_name,units=plot_units, epochs = epoch)\n",
    "    plot_single_resolution(Y_test_use[:,true_index]*maxabs_factor,\\\n",
    "                    Y_test_predicted[:,NN_index]*maxabs_factor,\\\n",
    "                   minaxis=-2*maxval,maxaxis=maxval*2,\n",
    "                   save=save,savefolder=save_folder_name,\\\n",
    "                   variable=plot_name,units=plot_units, epochs = epoch)\n",
    "    plot_bin_slices(Y_test_use[:,true_index]*maxabs_factor, Y_test_predicted[:,NN_index]*maxabs_factor,\\\n",
    "                    use_fraction = use_frac,\\\n",
    "                    bins=10,min_val=minval,max_val=maxval,\\\n",
    "                    save=True,savefolder=save_folder_name,\\\n",
    "                    variable=plot_name,units=plot_units, epochs = epoch)\n",
    "    if compare_reco:\n",
    "        plot_single_resolution(Y_test_use[:,true_index]*maxabs_factor,\\\n",
    "                   Y_test_predicted[:,NN_index]*maxabs_factor,\\\n",
    "                   use_old_reco = True, old_reco = reco_test_use[:,true_index],\\\n",
    "                   minaxis=-2*maxval,maxaxis=maxval*2,\n",
    "                   save=save,savefolder=save_folder_name,\\\n",
    "                   variable=plot_name,units=plot_units, epochs = epoch,reco_name=reco_name)\n",
    "        plot_bin_slices(Y_test_use[:,true_index]*maxabs_factor, Y_test_predicted[:,NN_index]*maxabs_factor,\\\n",
    "                    old_reco = reco_test_use[:,true_index],\\\n",
    "                    use_fraction = use_frac,\\\n",
    "                    bins=10,min_val=minval,max_val=maxval,\\\n",
    "                    save=True,savefolder=save_folder_name,\\\n",
    "                    variable=plot_name,units=plot_units, epochs = epoch,reco_name=reco_name)\n",
    "    if first_var == \"energy\" and num ==0:\n",
    "        plot_2D_prediction_fraction(Y_test_use[:,true_index]*maxabs_factor,\\\n",
    "                        Y_test_predicted[:,NN_index]*maxabs_factor,\\\n",
    "                        save,save_folder_name,bins=bins,\\\n",
    "                        minval=0,maxval=2,\\\n",
    "                        variable=plot_name,units=plot_units)\n",
    "    if num > 0 or first_var == \"zenith\":\n",
    "        plot_bin_slices(Y_test_use[:,true_index], Y_test_predicted[:,NN_index], \\\n",
    "                       energy_truth=Y_test_use[:,0]*max_energy, \\\n",
    "                       use_fraction = False, \\\n",
    "                       bins=10,min_val=min_energy,max_val=max_energy,\\\n",
    "                       save=True,savefolder=save_folder_name,\\\n",
    "                       variable=plot_name,units=plot_units, epochs=epoch)\n",
    "        if compare_reco:\n",
    "            plot_bin_slices(Y_test_use[:,true_index], Y_test_predicted[:,NN_index], \\\n",
    "                       energy_truth=Y_test_use[:,0]*max_energy, \\\n",
    "                       old_reco = reco_test_use[:,true_index],\\\n",
    "                       use_fraction = False, \\\n",
    "                       bins=10,min_val=min_energy,max_val=max_energy,\\\n",
    "                       save=True,savefolder=save_folder_name,\\\n",
    "                       variable=plot_name,units=plot_units, epochs = epoch,reco_name=reco_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
